# -*- coding: utf-8 -*-
"""magclassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bcAxWnh2V9GSHYVo85IRMkATfG4uVLoM

기본 함수
"""

import numpy as np
from enum import Enum
from matplotlib import pyplot as plt
import pandas as pd
import os
import pickle
import joblib 


def save_model(model, model_name):
  saved_model = pickle.dumps(model)
  print(model_name)
  joblib.dump(model, '{}.pkl'.format(model_name)) 

def load_model(model_name):
  model = joblib.load('{}.pkl'.format(model_name)) 
  return model

"""File Pre-processing"""

class Feature():
  def __init__(self, label, data, path):
    self.label = label
    self.data = data
    self.path = path

class Data():
  def __init__(self, path, sensor_value, stb_lst, diff):
    self.path= path
    self.sensor_value = sensor_value
    self.stb_lst = stb_lst
    self.diff = diff

class DataCollection():
  def __init__(self):
    self.data_dic = {}
  
  def add(self, data):
    self.data_dic[data.path] = data
  
  def find(self, path):
    return self.data_dic[path]

class FileManager():
  '''
  input : file path
  output : 3-axis sensor value list, label
  '''

  def __init__(self, path):
    self._files = self._process(path)

  def __len__(self):
    return len(self._files)

  def _csv_to_list(self, file):
    data = pd.read_csv(file + "/Magnetometer.csv")
    res = []
    
    res.append(data['X (µT)'].tolist())
    res.append(data['Y (µT)'].tolist())
    res.append(data['Z (µT)'].tolist())

    return res
  
  def _path_process(self, paths):
    res = []

    # paths : NewDatas/Label
    for path in paths:
      label = path.split('/')[-1]
      plist = os.listdir(path)
      plist.sort()

      # plist : NewData/
      for p in plist:
        fp = path + "/" + p
        data = self._csv_to_list(fp)
        res.append(Feature(label, data, fp))
    
    return res


  def _process(self, path):
    path_lst = os.listdir(path)
    res = []

    for p in path_lst:
      res.append(path + "/" + p)

    res = self._path_process(res)
    return res

  def __getitem__(self, index):
    # res = self._csv_to_list(self._files[index])
    # label = self._files[index].split('/')[-1]
    # label = label.split('_')[0]
    feature = self._files[index]
    
    return self._files[index]

"""Stable한 구간 & Difference"""

class DataProcess():
  STABLE = 0
  UNSTABLE = 1

  def __init__(self, fm, name_print = True):
    self._file_manager = fm
    self.name_print = name_print
    self.data_collection = DataCollection()
  
  def __len__(self):
    return len(self._file_manager)

  def _is_stable(self, data, threshold = 0.5):
    var = np.array(data).var()

    return True if var < threshold else False

  def _process(self, data):
    res = []

    # Each axis
    for axis in data:
      # Each data
      each = []
      for i in range(len(axis)-50):  
        each.append(self.STABLE if self._is_stable(axis[i:i+50]) else self.UNSTABLE)
      res.append(each)

    return res

  def _diff_mean(self, diff):
    res = []
    #print(diff)
    for i in range(len(diff)):
      res.append(sum(diff[i])/len(diff[i]))

    return res
  
  def _diff_sub(self, data):
    res = []
    #print("data sub : ", data)
    for i in range(3):
      res.append(data[1][i]-data[0][i])
    return res

  def _find_difference(self, data, stb_lst, label, status_max_count = 20):
    res = []
    status = self.STABLE
    status_count = 0
    axis_mean = [[], [], []]
    diff = []

    for i in range(len(stb_lst[0])):
      stable_count = 0
      for j in range(3):
        if stb_lst[j][i] != status:
          stable_count+=1

        if stable_count == 3:
          # status 관련 if
          if status_count != status_max_count:
            status_count += 1
          else:
            status = stb_lst[j][i]
            status_count = 0
            if status == self.UNSTABLE:
              diff.append(self._diff_mean(axis_mean))
              axis_mean[:] = [[], [], []]
            break

          # diff 관련 if
        if status == self.STABLE:
          axis_mean[j].append(data[j][i])

      if stable_count != 3 and status_count != 0:
          status_count = 0 
      
      res.append(status)

    
    diff.append(self._diff_mean(axis_mean))

    # stable list, difference value, label
    return np.array(res), self._diff_sub(diff), label

  def __getitem__(self, index):
    feature = self._file_manager[index]
    sensor_value, label = feature.data, feature.label
    if self.name_print == True:
      print(feature.path)
      
    states = self._process(sensor_value)
    res = self._find_difference(sensor_value, states, label)

    self.data_collection.add(Data(feature.path, sensor_value, res[0], res[1]))

    return res

"""Augmentation"""

import random
from copy import deepcopy

def random_value(value, s = 100):
  random.seed(s)
  return random.uniform(-1.0, 1.0) + value

def augment(data, t = 3.0):
  lst = [0.01, 1, -1]
  res = []
  #print("Before Augment : ", data)

  for z in lst:
    for y in lst:
      for x in lst:
        tmp = deepcopy(data)
        #print(tmp)
        tmp[0] += random_value(t*x)
        tmp[1] += random_value(t*y)
        tmp[2] += random_value(t*z)
        #print("({}, {}, {}) => ".format(x, y, z), tmp)
        res.append(tmp)

  return res

"""Dataset"""

import math
import random
from copy import deepcopy

def make_dataset_aug(datas):
  len_dict = {}
  data_dict = {'magX' : [], 'magY' : [], 'magZ' : [], 'Label' : []}
  res_dict = {'magX' : [], 'magY' : [], 'magZ' : [], 'Label' : [], 'total' : []}
  mag_lst = ['magX', 'magY', 'magZ']

   # Join same label's value
  for data in datas:
    X, y = data[1], data[2]

    print(y, X)
    if y in len_dict:
      idx = data_dict['Label'].index(y)

      for i, mag in enumerate(mag_lst):
        data_dict[mag][idx] = (data_dict[mag][idx] * len_dict[y] + X[i])/(len_dict[y] + 1)

      len_dict[y] += 1

    else:
      for i, mag in enumerate(mag_lst):
        data_dict[mag].append(X[i])
      data_dict['Label'].append(y)
      len_dict[y] = 1

  len_labels = len(data_dict['Label'])
  # Augment data
  # for i in range(len_labels):
  #   aug_lst = augment([data_dict[mag][i] for mag in mag_lst])
    
  #   for aug in aug_lst:
  #     total = 0
  #     for j, mag in enumerate(mag_lst):
  #       res_dict[mag].append(aug[j])
  #       total += math.pow(aug[j], 2)
      
  #     res_dict['total'].append(math.sqrt(total))
  #     res_dict['Label'].append(data_dict['Label'][i])

  return pd.DataFrame(res_dict)



def make_dataset(datas):
  #data_dict = {'magX' : [], 'magY' : [], 'magZ' : [], 'Label' : [], 'total' : []}
  data_dict = {'magX' : [], 'magY' : [], 'magZ' : [], 'Label' : []}
  mag_lst = ['magX', 'magY', 'magZ']

  for data in datas:
    X, y = data[1], data[2]

    total = 0
    for i, mag in enumerate(mag_lst):
      data_dict[mag].append(X[i])
      total += math.pow(X[i], 2)
    #data_dict['total'].append(math.sqrt(total))
    data_dict['Label'].append(y)
  
  return pd.DataFrame(data_dict)


def make_test_dataset(datas):
  #tmp = {'magX' : [], 'magY' : [], 'magZ' : [], 'total' : []}
  tmp = {'magX' : [], 'magY' : [], 'magZ' : []}
  labels = []
  for data in datas:
    X, y = data[1], data[2]
    labels.append(y)

    total = 0
    for i, mag in enumerate(['magX', 'magY', 'magZ']):
      tmp[mag].append(X[i])
      total += math.pow(X[i], 2)
    
    #tmp['total'].append(math.sqrt(total))

  return pd.DataFrame(tmp), labels


def df_add(lst):
  res = {'magX' : [], 'magY' : [], 'magZ' : []}
  mag = ['magX', 'magY', 'magZ']

  for data in lst:
    for m in mag:
      res[m].extend(data[m])

  return pd.DataFrame(res)


"""Confusion matrix"""

import itertools

def plot_confusion_matrix(con_mat, labels, title='Confusion Matrix', cmap=plt.cm.get_cmap('Blues'), normalize=False):
    fig, ax = plt.subplots(figsize=(7, 7))
    ax.imshow(con_mat, interpolation='nearest', cmap=cmap)
    plt.imshow(con_mat, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    marks = np.arange(len(labels))
    nlabels = []
    for k in range(len(con_mat)):
        n = sum(con_mat[k])
        nlabel = '{0}(n={1})'.format(labels[k],n)
        nlabels.append(nlabel)
    plt.xticks(marks, labels, rotation = 45, fontsize = 7)
    plt.yticks(marks, nlabels)

    thresh = con_mat.max() / 2.
    if normalize:
        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):
            plt.text(j, i, '{0}%'.format(con_mat[i, j] * 100 / n), horizontalalignment="center", color="white" if con_mat[i, j] > thresh else "black")
    else:
        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):
            plt.text(j, i, con_mat[i, j], horizontalalignment="center", color="white" if con_mat[i, j] > thresh else "black")
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

def add_df(df_lst):
  '''
  input : dataset list
  output : sum of dataset
  '''
  
  keys= ['magX', 'magY', 'magZ', 'Label']
  data_dic = {'magX' : [], 'magY' : [], 'magZ' : [], 'Label' : []}

  for key in keys:
    for df in df_lst:
        data_dic[key].extend(df[key])

  return pd.DataFrame(data_dic)


def get_df(path):
  fm = FileManager(path)
  datas = DataProcess(fm, name_print = False)
  print("Data len : ", len(datas))

  df = make_dataset(datas)

  return df

def get_dp(path, is_print = False):
  fm = FileManager(path)
  datas = DataProcess(fm, name_print = is_print)
  print("Data len : ", len(datas))

  return datas

from matplotlib import pyplot as plt
    

def df_drop_label(df, label):
    drops = []
    mag = ['magX', 'magY', 'magZ', 'Label']
    new_df = pd.DataFrame({m : [] for m in mag})
    
    lst = df['Label'].tolist()
    
    for i in range(len(lst)):
        if lst[i] == label:
            drops.append(i)
    
    for m in mag:
        new_df[m] = df[m].drop(drops)
    return new_df